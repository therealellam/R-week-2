---
title: "UNDERSTANDING CUSTOMER BEHAVIOUR BY UNSUPERVISED LEARNING USING R"
output: html_document
---

## PROBLEM DEFINITION

Kira Plastinina is a Russian brand that is sold through a defunct chain of retail stores in Russia, Ukraine, Kazakhstan, Belarus, China, Philippines, and Armenia. The brand’s Sales and Marketing team would like to understand their customer’s behavior from data that they have collected over the past year. More specifically, they would like to learn the characteristics of customer groups.

## DATA SOURCING

The dataset for this Independent project can be found here [http://bit.ly/EcommerceCustomersDataset].  

- The dataset consists of 10 numerical and 8 categorical attributes. The 'Revenue' attribute can be used as the class label.
- "Administrative", "Administrative Duration", "Informational", "Informational Duration", "Product Related" and "Product Related Duration" represents the number of different types of pages visited by the visitor in that session and total time spent in each of these page categories. The values of these features are derived from the URL information of the pages visited by the user and updated in real-time when a user takes an action, e.g. moving from one page to another. 
- The "Bounce Rate", "Exit Rate" and "Page Value" features represent the metrics measured by "Google Analytics" for each page in the e-commerce site. 
- The value of the "Bounce Rate" feature for a web page refers to the percentage of visitors who enter the site from that page and then leave ("bounce") without triggering any other requests to the analytics server during that session. 
- The value of the "Exit Rate" feature for a specific web page is calculated as for all pageviews to the page, the percentage that was the last in the session.
- The "Page Value" feature represents the average value for a web page that a user visited before completing an e-commerce transaction. 
- The "Special Day" feature indicates the closeness of the site visiting time to a specific special day (e.g. Mother’s Day, Valentine's Day) in which the sessions are more likely to be finalized with the transaction. The value of this attribute is determined by considering the dynamics of e-commerce such as the duration between the order date and delivery date. For example, for Valentina’s day, this value takes a nonzero value between February 2 and February 12, zero before and after this date unless it is close to another special day, and its maximum value of 1 on February 8. 
- The dataset also includes the operating system, browser, region, traffic type, visitor type as returning or new visitor, a Boolean value indicating whether the date of the visit is weekend, and month of the year.

## CHECKING THE DATA

## We first call the data.table library to be able to work with tabular data
```{r}
library("data.table")

my_data <- read.csv("C:\\Users\\ADMIN\\Downloads\\online_shoppers_intention.csv")

# First check have a look at the data set.

head(my_data)
```
```{r}
nrow(my_data)
ncol(my_data)
```


## PERFOMING DATA CLEANING

## We then check for the total number of missing values in each of the coulmns in our dataset using the colSums function
```{r}
colSums(is.na(my_data))
```

## Removing missing values in the dataframe
```{r}
na.omit(my_data)
```

## Identifying the numeric class in the data and evaluating if there are any outliers
```{r}
str(my_data)
```

##Checking for Outliers
```{r}
boxplot.stats(my_data$'Administrative')$out
boxplot.stats(my_data$'Administrative_Duration')$out
boxplot.stats(my_data$'Informational')$out
boxplot.stats(my_data$'Informational_Duration')$out
boxplot.stats(my_data$'ProductRelated')$out
boxplot.stats(my_data$'ProductRelated_Duration')$out
```

##Dealing with Duplicates
```{r}
new_data <- unique(my_data)
```

```{r}
nrow(new_data)
```
##UNIVARIATE ANALYSIS

1. Measures of Central tendency
## Mean
```{r}
#Average times a person visited the Administrative page
print(paste("The average times a person visited the Administrative page is",mean(new_data$Administrative)))

#Average duration a person spent on the Administrative page
print(paste("The duration a person spent on the Administrative page is ",mean(new_data$Administrative_Duration)))

#Average times a person visited the Informational page
print(paste("The average times a person visited the Informational page is",mean(new_data$`Informational`)))

#Average duration a person spent on the Informational page
print(paste("The duration a person spent on the Informational page is ",mean(new_data$Informational_Duration)))

#Average times a person visited the ProductRelated page
print(paste("The average times a person visited the ProductRelated page is",mean(new_data$`ProductRelated`)))

#Average duration a person spent on the ProductRelated page
print(paste("The duration a person spent on the ProductRelated page is ",mean(new_data$ProductRelated_Duration)))
```

```{r}
install.packages("tidyverse")
library(dplyr)
new_data %>% distinct()
```
```{r}
library(tidyr)
new_data %>% drop_na()
```


```{r}
colSums(is.na(new_data))
```

##Using Mice package to better understand missing values
```{r}
install.packages("mice")
library(mice)
md.pattern(new_data,plot = TRUE,rotate.names = TRUE)
```

Imputing any missing values using the mice function
```{r}
# Assessing the imputation methods for mice
methods(mice)
```
 Imputing using the mice function
```{r}
# Using random forest as the imputation method as most of our missing values are discrete
new_data_full<-mice(new_data,m=5,
                       method="rf",
                       maxit = 50,seed = 50)
```

```{r}
new_data<- complete(new_data_full,1)
```


##Univariate Graphic
```{r}
boxplot(new_data$`Administrative`, main="Administrative")
boxplot(new_data$`Administrative_Duration`, main="Administrative Duration")
boxplot(new_data$`Informational`, main="Informational")
boxplot(new_data$`BounceRates`, main="BounceRates")
boxplot(new_data$`ExitRates`, main="ExitRates")
boxplot(new_data$`PageValues`, main="PageValues")
boxplot(new_data$`ProductRelated`, main="Product Related")

```
##Bar Plots
```{r}
barplot(table(new_data$Administrative), main = "Bar Plot of Administrative page visits")
barplot(table(new_data$Informational), main = "Bar Plot of Informational page visits")
barplot(table(new_data$ProductRelated), main = "Bar Plot of Product Related visits")
```
##Histogram

```{r}
hist(new_data$ BounceRates, main= "Histogram of Bounce Rates")
```

```{r}
# Administrative plots
density_plot(new_data,1,"Distribution of visitors in Administration page")
```
```{r}
# Informative page distribution
density_plot(new_data,3,"The Distribution of vistors in informative pages")
```

```{r}
# Product page distribution
density_plot(new_data,5,"Distribution of visitors on Product related pages")
```

```{r}
# Distribution of Special days- closeness of a sites visiting time to a special day
density_plot(new_data,10,"Distribution of Special day proximity")
```
#For Discrete variables
```{r}
barplot(table(new_data$Month),main="Frequency of visitors per month",col = "blue",ylab = "count of visitors")
```
##BIVARIATE ANALYSIS

```{r}
# Assessign the correlation

library("dplyr") 
nums<-select_if(new_data,is.numeric)

install.packages("corrplot")
library(corrplot)
corrplot(cor(nums),method = "circle",type="upper")
```
##Relship on Exit Rate and visits on the Administrative page
```{r}
plot(new_data$Administrative,new_data$ExitRates,main="Relship on Exit Rate and visits on the Administrative page",col = "blue",xlab = "Administrative Page visits",ylab = "Exit rates")
```

##MODELING

K-Means Clustering

#Creating a normalization function

```{r}
nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
```

##applying the normalization function to our data table
```{r}
ad_nor <- as.data.frame(lapply(new_data[,c(1,2,3,4,5,6,7,8,9,10,12,13,14,15)], nor))
```

##Applying the K-means clustering algorithm with no. of centroids(k)=3
```{r}
result<- kmeans(ad_nor,3,iter.max = 5) 

```

##Visualizing
```{r}
install.packages("cluster")
library("cluster")
```
```{r}
install.packages("factoextra")

```
```{r}
library("factoextra")
fviz_cluster(result,data=ad_nor)
```
##HIERACHICAL MODEL
```{r}
?hclust
```


```{r}
# Getting the distance to be used to locate points
dist<-dist(ad_nor,method = "euclidian")

```
```{r}
# Hierarchical model
h_model<-hclust(dist,method = "complete")
# Plotting the dendrogram to visualize the similarity between points
h_model
```

